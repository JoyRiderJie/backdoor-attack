

# backdoor-attack

This Github repository summarizes a list of **Backdoor Learning** resources.I will try my best to continuously maintain this Github Repository in a monthly manner.

#### Why is Backdoor Learning?

Backdoor learning is an emerging research area, which discusses the security issues of the training process towards machine learning algorithms. It is critical for safely adopting third-party training resources or models in reality.

Note: 'Backdoor' is also commonly called the 'Neural Trojan' or 'Trojan'.

---

## ATTACK

### TPAMI

#### 2024

* Robust and Transferable Backdoor Attacks Against Deep Image Compression With Selective Frequency Prior‚öîÔ∏è      [paper](https://ieeexplore.ieee.org/document/10771646)



---

### CVPR 

#### 2024

* BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning‚öîÔ∏è    [paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liang_BadCLIP_Dual-Embedding_Guided_Backdoor_Attack_on_Multimodal_Contrastive_Learning_CVPR_2024_paper.html) |  [code](https://github.com/LiangSiyuan21/BadCLIP)

* BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP‚öîÔ∏è   [paper](https://openaccess.thecvf.com/content/CVPR2024/html/Bai_BadCLIP_Trigger-Aware_Prompt_Learning_for_Backdoor_Attacks_on_CLIP_CVPR_2024_paper.html)    |     [code](https://github.com/jiawangbai/BadCLIP)



----

### ICLR

#### 2024

*  Universal Backdoor Attacks‚öîÔ∏è  [paper](https://openreview.net/forum?id=3QkzYBSWqL)|  [code](https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks)

---

### ICML 

#### 2024

* Generalization Bound and New Algorithm for Clean-Label Backdoor Attack     [paper](https://openreview.net/forum?id=ZdqiT0McON)    | [code](https://github.com/hong-xian/backdoor-attack.git)
* A Theoretical Analysis of Backdoor Poisoning Attacks in Convolutional Neural Networks     [paper](https://openreview.net/forum?id=SfcB4cVvPz) 
* Causality Based Front-door Defense Against Backdoor Attack on Language Models üõ°Ô∏è        [paper](https://openreview.net/forum?id=dmHHVcHFdM) |     [code](https://github.com/lyr17/Frontdoor-Adjustment-Backdoor-Elimination)
* ‚Äã    

----

### NeurIPS

#### 2024

* Data Free Backdoor Attacks‚öîÔ∏è       [paper](https://papers.nips.cc/paper_files/paper/2024/file/2a7e91c6e4b68325d9884a7469804837-Paper-Conference.pdf)    |   [code](https://github.com/AAAAAAsuka/DataFree_Backdoor_Attacks)
* WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks‚öîÔ∏è    [paper](https://papers.nips.cc/paper_files/paper/2024/hash/4ce18228ececb78bca04cbce069891b1-Abstract-Conference.html)    |    [code](https://github.com/BililiCode/WaveAttack)
* BackTime: Backdoor Attacks on Multivariate Time Series Forecasting‚öîÔ∏è    [paper](https://papers.nips.cc/paper_files/paper/2024/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html)  |    [code](https://github.com/xiaolin-cs/BackTime)

* Causality Based Front-door Defense Against Backdoor Attack on Language Models    [paper](https://openreview.net/forum?id=dmHHVcHFdM)    |    [code](https://github.com/lyr17/Frontdoor-Adjustment-Backdoor-Elimination)

* Defense against Backdoor Attack on Pre-trained Language Models via Head Pruning and Attention Normalization    [paper](https://openreview.net/forum?id=1SiEfsCecd)   |    [code](https://github.com/xingyizhao/PURE)

* BD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency    [paper](https://openreview.net/forum?id=YCzbfs2few)   |   [code](https://github.com/THUYimingLi/BackdoorBox)

* Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks    [paper](https://openreview.net/forum?id=ycLHJuLYuD)   |     [code](https://github.com/BigML-CS-UCLA/SafeCLIP)

* Energy-based Backdoor Defense without Task-Specific Samples and Model Retraining    [paper](https://openreview.net/forum?id=TJ6tVNt6Y4)   |  [code](https://github.com/ifen1/EBBA)

* Generalization Bound and New Algorithm for Clean-Label Backdoor Attack    [paper](https://openreview.net/forum?id=ZdqiT0McON)   | [paper](https://github.com/hong-xian/backdoor-attack)

----

### ACL

#### 2024

*  Acquiring Clean Language Models from Backdoor Poisoned Datasets üõ°Ô∏è  [paper](https://aclanthology.org/2024.acl-long.441.pdf)    |     [code](https://github.com/ZrW00/MuScleLoRA)

* BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents‚öîÔ∏è     [paper](https://aclanthology.org/2024.acl-long.530.pdf)    |     [code](https://github.com/DPamK/BadAgent)

* BadActs: A Universal Backdoor Defense in the Activation Spaceüõ°Ô∏è     [paper](https://aclanthology.org/2024.findings-acl.317.pdf)    | [code](https://github.com/clearloveclearlove/BadActs)

* UOR: Universal Backdoor Attacks on Pre-trained Language Models     [paper](https://aclanthology.org/2024.findings-acl.468/)     | 

---

### IJCAL

#### 2024

* BadFusion: 2D-Oriented Backdoor Attacks against 3D Object Detection‚öîÔ∏è     [paper](https://www.ijcai.org/proceedings/2024/39)  
* BADFSS: Backdoor Attacks on Federated Self-Supervised Learning ‚öîÔ∏è    [paper](https://www.ijcai.org/proceedings/2024/61)

# others

* 2024ACL-ARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection [paper](https://aclanthology.org/2024.acl-long.725.pdf)   |    [code](https://github.com/anudeex/WARDEN/blob/main/preparation/word_count.py)

---

* Unicode: attack-‚öîÔ∏è ;  defense-üõ°Ô∏è 
